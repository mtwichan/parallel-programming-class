{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "A6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UBCO-COSC-407-Winter-2021-Term-1/lab-6---introduction-to-cuda-mtwichan/blob/main/A6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JrIevO5mEoV"
      },
      "source": [
        "# A6 (10 Marks)\n",
        "---\n",
        "**Focus**: CUDA Basics - Introduction (Warming Up!!)\n",
        "\n",
        "© 2021 Dr. Scott Fazackerley (Based on labs from Dr. Abdallah Mohamed © 2020)\n",
        "\n",
        "For this course, we are going to be using Google Colab version and takes advantage of the free Cloud GPUs offered through the platform for CUDA development. Colab Notebooks (you're reading one right now!) are typically designed to run Python code, however, we'll be modifying them in such a way that we can run CUDA code (as discussed in the lectures) on the GPU.\n",
        "\n",
        "Please note that your code will be written and run directly within this assignment. You will need to save a local copy and ensure that you save and upload your completed notebook to your GitHub repo for submission.   You will also need to provide screenshots of output in many cases for submissions.  \n",
        "\n",
        "**CRITICAL**\n",
        "Lastly, keep in mind that anytime your runtime disconnects or is restarted **you must re-run the Notebook Setup code block**. This applies to all CUDA assignments done using Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hd9jjAb30WQ"
      },
      "source": [
        "## Notebook Setup: GPU Runtime\n",
        "\n",
        "Before writing/running any CUDA code, we need to ensure Colab is provisioning a Cloud GPU for us. To do this, click on the \"Runtime\" menu item in the top bar and select the \"Change runtime type\" option. Select \"GPU\" from the list of Hardware accelerators and click \"Ok\". \n",
        "\n",
        "## Notebook Setup: CUDA Compilation\n",
        "\n",
        "To enable CUDA code compilation on Colab Notebooks, we'll employ use of the NVCC4Jupyter plugin (source code/documentation available [here](https://github.com/UBCO-COSC-407-Winter-2021-Term-1/nvcc4jupyter). This plugin effectively turns any Colab Notebook code block that includes `%%cu` into compilable/runnable CUDA code.\n",
        "\n",
        "To download/install/enable NVCC4Jupyter, please run the following code block. **Running this block is required anytime you connect/restart/reconnect to an instance.** To run a code block, mouse over it and click the play button on left side.\n",
        "\n",
        "You should see some output when you click the play button. Wait until the code block is finished running (this is indicated when the stop button goes away). The last couple lines of output should look something like the following:\n",
        "\n",
        "```\n",
        "created output directory at /content/src\n",
        "Out bin /content/result.out\n",
        "```\n",
        "\n",
        "If your last two lines of output look something like above, you're ready to begin the assignment!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3R3aMhww6WKU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c332772-66b7-439c-cf11-379aced75b12"
      },
      "source": [
        "# Run the following to configure your notebook for CUDA code\n",
        "!pip install git+git://github.com/UBCO-COSC-407-Winter-2021-Term-1/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+git://github.com/UBCO-COSC-407-Winter-2021-Term-1/nvcc4jupyter.git\n",
            "  Cloning git://github.com/UBCO-COSC-407-Winter-2021-Term-1/nvcc4jupyter.git to /tmp/pip-req-build-2gn_dciv\n",
            "  Running command git clone -q git://github.com/UBCO-COSC-407-Winter-2021-Term-1/nvcc4jupyter.git /tmp/pip-req-build-2gn_dciv\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4405 sha256=1b57e9dd5762efd397a4d7316fb77ffcd433e2f68554fd026d808c341b00fdba\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5l_bsd62/wheels/a5/e9/0b/81648e44e04e6ae47e0ec176f5c1805063e4f687ee2bfceca6\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6I7-EHCnSB_"
      },
      "source": [
        "## Question 1. [+3] \n",
        "\n",
        "Querying your GPU: In this question, you will run simple query code to discover the properties and limits of your Colab-provisioned NVIDIA card. Run the code block below, then capture your answers and **submit** them as an image file named A6_Q1.png.  This is important as we will want to know what resources are available on a card. \n",
        "\n",
        "**Note:** See below that `%%cu` needs to be added to let Colab know that the code block is CUDA code.\n",
        "\n",
        "*Marking Guide: +3 for a screenshot with the required info*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTKcmsc8_khE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7816dc4f-0163-47e4-ac6a-ba213901f0ca"
      },
      "source": [
        "%%cu\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "#include <stdio.h>\n",
        "\n",
        "int main()\n",
        "{\n",
        "    cudaDeviceProp prop;\n",
        "    int count;\n",
        "    cudaGetDeviceCount(&count);\n",
        "    for (int i = 0; i < count; i++)\n",
        "    {\n",
        "        cudaGetDeviceProperties(&prop, i);\n",
        "        printf(\"----- General Information for device %d ---\\n\", i);\n",
        "        printf(\"Name:\t%s\\n\", prop.name);\n",
        "        printf(\"Compute capability:\t%d.%d\\n\", prop.major, prop.minor);\n",
        "        printf(\"Clock rate:\t%d\\n\", prop.clockRate);\n",
        "        printf(\"Device copy overlap:\t\");\n",
        "        printf(prop.deviceOverlap ? \"Enabled\\n\" : \"Disabled\\n\");\n",
        "        printf(\"Kernel execution timeout: \");\n",
        "        printf(prop.kernelExecTimeoutEnabled ? \"Enabled\\n\" : \"Disabled\\n\");\n",
        "        printf(\"----- Memory Information for device %d ---\\n\", i);\n",
        "        printf(\"Total global mem:\t%lu\\n\", prop.totalGlobalMem);\n",
        "        printf(\"Total constant Mem:\t%ld\\n\", prop.totalConstMem);\n",
        "        printf(\"Max mem pitch:\t%ld\\n\", prop.memPitch);\n",
        "        printf(\"Texture Alignment:\t%ld\\n\", prop.textureAlignment);\n",
        "        printf(\"----- MP Information for device %d ---\\n\", i);\n",
        "        printf(\"Multiprocessor count:\t%d\\n\", prop.multiProcessorCount);\n",
        "        printf(\"Shared mem per mp:\t%ld\\n\", prop.sharedMemPerBlock);\n",
        "        printf(\"Registers per mp:\t%d\\n\", prop.regsPerBlock);\n",
        "        printf(\"Threads in warp:\t%d\\n\", prop.warpSize);\n",
        "        printf(\"Max threads per block:\t%d\\n\", prop.maxThreadsPerBlock);\n",
        "        printf(\"Max thread dimensions:\t(%d, %d, %d)\\n\",\n",
        "               prop.maxThreadsDim[0], prop.maxThreadsDim[1], prop.maxThreadsDim[2]);\n",
        "        printf(\"Max grid dimensions:\t(%d, %d, %d)\\n\", prop.maxGridSize[0], prop.maxGridSize[1], prop.maxGridSize[2]);\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- General Information for device 0 ---\n",
            "Name:\tTesla K80\n",
            "Compute capability:\t3.7\n",
            "Clock rate:\t823500\n",
            "Device copy overlap:\tEnabled\n",
            "Kernel execution timeout: Disabled\n",
            "----- Memory Information for device 0 ---\n",
            "Total global mem:\t11996954624\n",
            "Total constant Mem:\t65536\n",
            "Max mem pitch:\t2147483647\n",
            "Texture Alignment:\t512\n",
            "----- MP Information for device 0 ---\n",
            "Multiprocessor count:\t13\n",
            "Shared mem per mp:\t49152\n",
            "Registers per mp:\t65536\n",
            "Threads in warp:\t32\n",
            "Max threads per block:\t1024\n",
            "Max thread dimensions:\t(1024, 1024, 64)\n",
            "Max grid dimensions:\t(2147483647, 65535, 65535)\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_z_NlOUrATP6"
      },
      "source": [
        "## Question 2. [+7]\n",
        "\n",
        "**Simple CUDA code:** consider this loop for initializing an array **a**:\n",
        "\n",
        "```c\n",
        "const int n = 10000000 // 10 million\n",
        "for (i = 0; i < n; i++)\n",
        "    a[i] = (double)i / n;\n",
        "```\n",
        "\n",
        "Submit:\n",
        "\n",
        "1.   The serial implementation running on the CPU.\n",
        "2.   The CUDA implementation (1 thread per array element).  In your implementation, you will need to ensure:\n",
        "    1. Memory on the card is correctly allocated (and the host as well)\n",
        "    2. Data is properly divided up as well as defining the number of blocks in a grid and the number of threads per block\n",
        "    3. Data is copied back from the card at the end of the kernel launch\n",
        "    4. Data on the card is free'd when you are done. \n",
        "\n",
        "In both cases, add code to print the first and last 5 elements of the array to verify your code.  Add a text block commenting on the timing results.\n",
        "\n",
        "*Note that you need to use the placeholder %.7f to print 7 digits after the decimal point.*\n",
        "\n",
        "***Sample output:***\n",
        "\n",
        "```c\n",
        "a[0]: 0.0000000\n",
        "a[1]: 0.0000001\n",
        "a[2]: 0.0000002\n",
        "a[3]: 0.0000003\n",
        "a[4]: 0.0000004\n",
        "...\n",
        "a[9999995]: 0.9999995 \n",
        "a[9999996]: 0.9999996 \n",
        "a[9999997]: 0.9999997 \n",
        "a[9999998]: 0.9999998 \n",
        "a[9999999]: 0.9999999\n",
        "```\n",
        "\n",
        "***Note***:  You can find details on timing CUDA code at: https://developer.nvidia.com/blog/how-implement-performance-metrics-cuda-cc/ and https://programmerfish.com/profiling-cuda-kernels-and-wrapper-functions/.\n",
        "\n",
        "***Marking Guide:***\n",
        "+2 for the kernel function\n",
        "+3 for launch configuration and properly calling the kernel\n",
        "+2 for measuring the time of the parallel and serial code  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyqpuDM2CX6K"
      },
      "source": [
        "### CPU Implementation\n",
        "\n",
        "Please code and run your CPU implementation in the code block below. When submitting your assignment, please copy the code block into a text/c file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lpli5URsCtPx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ec62165-2d5f-450e-c5f6-dd47161ea8f0"
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "\n",
        "int main(void) {\n",
        "    const int n = 10000000;\n",
        "    int i = 0;\n",
        "    int idx = 0;\n",
        "    time_t start_t, end_t;\n",
        "\n",
        "    double *a = (double*) malloc(sizeof(double) * n);\n",
        "    \n",
        "    start_t = clock();\n",
        "    for (i = 0; i < n; i++) {\n",
        "        a[i] = (double)i / n;   \n",
        "    }\n",
        "    end_t = clock();\n",
        "    \n",
        "    printf(\"Execution Time: %fs\\n\", ((double)(end_t - start_t) / CLOCKS_PER_SEC));\n",
        "    for (i = 0; i < 5; i++) {\n",
        "        printf(\"a[%d]: %.7f\\n\", i, a[i]);\n",
        "    }\n",
        "\n",
        "    for (i = 5; i > 0; i--) {\n",
        "        idx = n - i;\n",
        "        printf(\"a[%d]: %.7f\\n\", idx, a[idx]);\n",
        "    }   \n",
        "}"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution Time: 0.094922s\n",
            "a[0]: 0.0000000\n",
            "a[1]: 0.0000001\n",
            "a[2]: 0.0000002\n",
            "a[3]: 0.0000003\n",
            "a[4]: 0.0000004\n",
            "a[9999995]: 0.9999995\n",
            "a[9999996]: 0.9999996\n",
            "a[9999997]: 0.9999997\n",
            "a[9999998]: 0.9999998\n",
            "a[9999999]: 0.9999999\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0froFiPCwgJ"
      },
      "source": [
        "### CUDA Implementation\n",
        "\n",
        "Please code and run your CUDA implementation in the code block below. When submitting your assignment, please copy the code block into a text/cu file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHHRVWZNC1Iu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02ee8279-3f93-4174-ea70-02ea71e4ad29"
      },
      "source": [
        "%%cu\n",
        "\n",
        "#include \"cuda_runtime.h\"\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "__global__ void assignArray(double* A, int N) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < N) {\n",
        "        A[i] = (double) (i);\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    const int N = 10000000;\n",
        "    float time = 0;\n",
        "    int i = 0, idx = 0;\n",
        "    int nBytes = N * sizeof(double);\n",
        "    int nthreads = 1024;\n",
        "    int nblocks = (N - 1) / nthreads + 1;\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    double* A = (double*) malloc(nBytes);  \n",
        "    double* d_A = NULL;\n",
        "  \n",
        "    cudaMalloc(&d_A, nBytes);\n",
        "    cudaMemcpy(d_A, A, nBytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "    assignArray <<<nblocks, nthreads>>> (d_A, N);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    cudaMemcpy(A, d_A, nBytes, cudaMemcpyDeviceToHost);\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "    printf(\"Execution Time: %fs\\n\", time / 1000.0);\n",
        "\n",
        "    for (i = 0; i < 5; i++) {\n",
        "        printf(\"a[%d]: %.7f\\n\", i, A[i]);\n",
        "    }\n",
        "\n",
        "    for (i = 5; i > 0; i--) {\n",
        "        idx = N - i;\n",
        "        printf(\"a[%d]: %.7f\\n\", idx, A[idx]);\n",
        "    } \n",
        "\n",
        "    free(A);\n",
        "    cudaFree(d_A);  \n",
        "}"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution Time: 0.000593s\n",
            "a[0]: 0.0000000\n",
            "a[1]: 1.0000000\n",
            "a[2]: 2.0000000\n",
            "a[3]: 3.0000000\n",
            "a[4]: 4.0000000\n",
            "a[9999995]: 9999995.0000000\n",
            "a[9999996]: 9999996.0000000\n",
            "a[9999997]: 9999997.0000000\n",
            "a[9999998]: 9999998.0000000\n",
            "a[9999999]: 9999999.0000000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETI-SVnhmUbt"
      },
      "source": [
        "Comments on timing results:\n",
        "The parallel program completed in 0.000593s whereas the sequential method completed in 0.094922s."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYLlFNpdDOOS"
      },
      "source": [
        "---\n",
        "\n",
        "**Submission Instructions**\n",
        "\n",
        "For this assignment, you need to do the following:\n",
        "\n",
        "1. Save your A6.ipynb file from Colab to GitHub.    Make sure that this file is saved (you have a copy) and it is successfully commited to your repo.   Ensure that your code solutions are in your Notebook as they will be marked from there. \n",
        "2. Add the PNG file from Q1 and the source code file.\n",
        "\n",
        "Note that you can resubmit an assignment, but the new submission overwrites the old submission and receives a new timestamp with GitHub.  Make sure to review the due date for this submission. "
      ]
    }
  ]
}